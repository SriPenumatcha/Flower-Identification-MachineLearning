{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUtcJ7fZoPlO"
   },
   "source": [
    "# The total, available, and used memory of the system in a readable format like \"GB\" or \"MB\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1722247923759,
     "user": {
      "displayName": "sri I",
      "userId": "05167453280339117545"
     },
     "user_tz": -600
    },
    "id": "g1TlBZjpl8Rs",
    "outputId": "0c9c9525-afdb-48be-91fd-df5126df503a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== Memory Info ========================================\n",
      "Total: 15.73GB\n",
      "Available: 7.55GB\n",
      "Used: 8.18GB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "def get_size(bytes, suffix=\"B\"):\n",
    "    factor = 1024\n",
    "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n",
    "        if bytes < factor:\n",
    "            return f\"{bytes:.2f}{unit}{suffix}\"\n",
    "        bytes /= factor\n",
    "print(\"=\"*40, \"Memory Info\", \"=\"*40)\n",
    "svmem = psutil.virtual_memory()\n",
    "print(f\"Total: {get_size(svmem.total)}\")\n",
    "print(f\"Available: {get_size(svmem.available)}\")\n",
    "print(f\"Used: {get_size(svmem.used)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFr39R_Fo5JQ"
   },
   "source": [
    "# Import Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22079,
     "status": "ok",
     "timestamp": 1722247952202,
     "user": {
      "displayName": "sri I",
      "userId": "05167453280339117545"
     },
     "user_tz": -600
    },
    "id": "bUFW_h81p3rp",
    "outputId": "e88c1acf-e6ff-4b82-ee32-99b4c3a59cd3"
   },
   "outputs": [],
   "source": [
    "# Update the path to a local directory where the 'flowers' dataset is located\n",
    "data_dir = 'flowers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2370,
     "status": "ok",
     "timestamp": 1722247959449,
     "user": {
      "displayName": "sri I",
      "userId": "05167453280339117545"
     },
     "user_tz": -600
    },
    "id": "DgXxfFjxqJut"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMfBseTguG55"
   },
   "source": [
    "# Loading the DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "executionInfo": {
     "elapsed": 372,
     "status": "error",
     "timestamp": 1722247966575,
     "user": {
      "displayName": "sri I",
      "userId": "05167453280339117545"
     },
     "user_tz": -600
    },
    "id": "5-G7vBmmuGZV",
    "outputId": "e47bd9ef-b16d-4270-dedc-1701ac4fa961"
   },
   "outputs": [],
   "source": [
    "# Load the data from the updated local directory\n",
    "data = load_files(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFxBXlTwE9as"
   },
   "source": [
    "# DATA Processing and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1722051475833,
     "user": {
      "displayName": "vrinda patel",
      "userId": "08474551777617258805"
     },
     "user_tz": -600
    },
    "id": "xw763_Nzqdfp",
    "outputId": "1a166fc5-2496-4654-cf88-8396d42c3a36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n"
     ]
    }
   ],
   "source": [
    "# List the content of the Folder\n",
    "folders = os.listdir(data_dir)\n",
    "print(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GTC91NhFu-4"
   },
   "source": [
    "# We have a folder for each flower class or type, and you want to load the data into two NumPy arrays:\n",
    "\n",
    "- X: Filenames (training data)\n",
    "- y: Flower names (target labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1722051480959,
     "user": {
      "displayName": "vrinda patel",
      "userId": "08474551777617258805"
     },
     "user_tz": -600
    },
    "id": "PGJQhDJIFpZH",
    "outputId": "861cf875-2097-405d-ff7d-6205ed5905a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data files -  ['flowers\\\\sunflower\\\\7176729016_d73ff2211e.jpg'\n",
      " 'flowers\\\\dandelion\\\\18385846351_3a2bf60427_n.jpg'\n",
      " 'flowers\\\\dandelion\\\\98992760_53ed1d26a9.jpg' ...\n",
      " 'flowers\\\\dandelion\\\\7184780734_3baab127c2_m.jpg'\n",
      " 'flowers\\\\sunflower\\\\10386540106_1431e73086_m.jpg'\n",
      " 'flowers\\\\sunflower\\\\164670176_9f5b9c7965.jpg']\n",
      "Target labels -  [3 1 1 ... 1 3 3]\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data['filenames'])\n",
    "y = np.array(data['target'])\n",
    "labels = np.array(data['target_names'])\n",
    "\n",
    "# Arrays\n",
    "print('Data files - ',X)\n",
    "print('Target labels - ',y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_DA3NXmzHOLv"
   },
   "source": [
    "The numbers in the **Target labels as [3 1 1 ... 1 3 3]** are corresponding to class label. We need to change them to a vector of 5 elements (5 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape y to a 2D array\n",
    "y_reshaped = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding\n",
    "y_onehot = encoder.fit_transform(y_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded target labels:\n",
      "[[0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Display the one-hot encoded target labels\n",
    "print('One-hot encoded target labels:')\n",
    "print(y_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkN0O9z4JG7r"
   },
   "source": [
    "## Removing the .pyc or .py files from X and y:\n",
    "- This loop iterates over the positions of .pyc or .py files found in the previous step.\n",
    "- np.delete(X, pos) removes the elements at the specified positions from the array X.\n",
    "- Similarly, np.delete(y, pos) removes the corresponding elements from the array y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Data files -  ['flowers\\\\sunflower\\\\7176729016_d73ff2211e.jpg'\n",
      " 'flowers\\\\dandelion\\\\18385846351_3a2bf60427_n.jpg'\n",
      " 'flowers\\\\dandelion\\\\98992760_53ed1d26a9.jpg' ...\n",
      " 'flowers\\\\dandelion\\\\7184780734_3baab127c2_m.jpg'\n",
      " 'flowers\\\\sunflower\\\\10386540106_1431e73086_m.jpg'\n",
      " 'flowers\\\\sunflower\\\\164670176_9f5b9c7965.jpg']\n",
      "Updated Target labels -  [3 1 1 ... 1 3 3]\n"
     ]
    }
   ],
   "source": [
    "# Find positions of .pyc or .py files in X\n",
    "pos = [i for i, filename in enumerate(X) if filename.endswith('.pyc') or filename.endswith('.py')]\n",
    "\n",
    "# Remove elements at the specified positions from X and y\n",
    "X = np.delete(X, pos)\n",
    "y = np.delete(y, pos)\n",
    "\n",
    "# Verify the updated X and y arrays\n",
    "print('Updated Data files - ', X)\n",
    "print('Updated Target labels - ', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UhSbHlSL2uE"
   },
   "source": [
    "# Loading the Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXwFt9amMMse"
   },
   "source": [
    "## Converts a list of image file paths into an array of image data, resizes the images, and prints the shape of the resulting array and the first training item. The steps include:\n",
    "- Importing necessary functions from Keras:\n",
    "- Defining the convert_img_to_arr function:\n",
    "- Converting the list of image arrays to a NumPy array:\n",
    "- Printing the shape of the array and the first training item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "def convert_img_to_arr(img_path, target_size):\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target size for resizing the images\n",
    "target_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of image file paths\n",
    "image_paths = ['flowers/sunflower/7176729016_d73ff2211e.jpg', 'flowers/dandelion/18385846351_3a2bf60427_n.jpg', ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ellipsis' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3230\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3231\u001b[1;33m         \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3232\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ellipsis' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7264\\4038867689.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Convert image paths to NumPy array of image data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimage_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconvert_img_to_arr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7264\\4038867689.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Convert image paths to NumPy array of image data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimage_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconvert_img_to_arr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7264\\529637119.py\u001b[0m in \u001b[0;36mconvert_img_to_arr\u001b[1;34m(img_path, target_size)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconvert_img_to_arr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3231\u001b[0m         \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3232\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3233\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3234\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ellipsis' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "# Convert image paths to NumPy array of image data\n",
    "image_data = np.array([convert_img_to_arr(img_path, target_size) for img_path in image_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of the image data array:', image_data.shape)\n",
    "print('First training item:')\n",
    "print(image_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25504,
     "status": "ok",
     "timestamp": 1722051515568,
     "user": {
      "displayName": "vrinda patel",
      "userId": "08474551777617258805"
     },
     "user_tz": -600
    },
    "id": "cydm6QzaL5tf",
    "outputId": "6fc11a90-a88c-41c9-a553-ff41f51d9d34"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'img_to_array' from 'keras.preprocessing.image' (C:\\Users\\linds\\anaconda3\\envs\\PythonData\\lib\\site-packages\\keras\\preprocessing\\image.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7264\\2577216836.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconvert_img_to_arr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'img_to_array' from 'keras.preprocessing.image' (C:\\Users\\linds\\anaconda3\\envs\\PythonData\\lib\\site-packages\\keras\\preprocessing\\image.py)"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "import numpy as np\n",
    "\n",
    "def convert_img_to_arr(file_path_list):\n",
    "    arr = []\n",
    "    #size=64,64\n",
    "    img_width, img_height = 150, 150\n",
    "    for file_path in file_path_list:\n",
    "        img = load_img(file_path, target_size=(img_width, img_height))\n",
    "        img = img_to_array(img)\n",
    "        arr.append(img)\n",
    "        #arr.append(cv2.resize(img,size))\n",
    "    return arr\n",
    "\n",
    "X = np.array(convert_img_to_arr(X))\n",
    "print(X.shape)\n",
    "print('First training item : ', X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6bI8CSVM9wZ"
   },
   "source": [
    "## **Key Points:**\n",
    "- The shape of training data is (4317, 150, 150, 3)\n",
    "- 4317 is the number of training items or files\n",
    "- (150,150) is the target size or image size provided while loading image\n",
    "- 3 refers to the depth for colored images ( RGB channels )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxzNm_GlN-Oa"
   },
   "source": [
    "# Have a look at some beautiful Flower Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "executionInfo": {
     "elapsed": 3219,
     "status": "ok",
     "timestamp": 1722051622726,
     "user": {
      "displayName": "vrinda patel",
      "userId": "08474551777617258805"
     },
     "user_tz": -600
    },
    "id": "L0lEhzfCNd9c",
    "outputId": "56a52e64-f34b-400d-d251-9ea34dd208a5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Debugging: Check data type and range\n",
    "print(f\"Data type of X: {X.dtype}\")\n",
    "print(f\"Min value in X: {X.min()}\")\n",
    "print(f\"Max value in X: {X.max()}\")\n",
    "\n",
    "# Debugging: Check label indexing\n",
    "print(f\"Labels: {y[:5]}\")\n",
    "print(f\"Corresponding folder names: {[folders[label] for label in y[:5]]}\")\n",
    "\n",
    "# Debugging: Check image shape\n",
    "print(f\"Shape of first image: {X[0].shape}\")\n",
    "\n",
    "fig = plt.figure(figsize=(16, 9))\n",
    "for i in range(5):\n",
    "    ax = fig.add_subplot(1, 5, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(X[i].astype(np.uint8))\n",
    "    ax.set_title(folders[y[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6wlXYn99DCz"
   },
   "outputs": [],
   "source": [
    "# rescale the training data\n",
    "X = X.astype('float32')/255\n",
    "# Confirming number of class\n",
    "num_classes = len(np.unique(y))\n",
    "print('Number of classes : ', num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y = to_categorical(y)\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# splite the data into subsets and explore their shapes\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "print('The test Data Shape ', X_test.shape[0])\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test,y_test, test_size = 0.5)\n",
    "print('The training Data Shape ', X_valid.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The train Data Shape ', X_train.shape[1:])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1Kjl_D3WEZQqKS-tTNatYKwArYIePfIGU",
     "timestamp": 1722247771896
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
